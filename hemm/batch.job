#!/bin/bash
#SBATCH --nodes=1
#SBATCH --gres=gpu:1
#SBATCH --mem=128GB
#SBATCH -p highmem
#SBATCH --output ./log-%x-%J-instruct_blip.txt
#SBATCH -c 5
#SBATCH -t 96:00:00

ulimit -v unlimited

# Kill all GPU processes before training, since there might be some "ghost" still running
kill -9 $(nvidia-smi | sed -n 's/|\s*[0-9]*\s*\([0-9]*\)\s*.*/\1/p' | sort | uniq | sed '/^$/d')

# conda activate /work/agoindan/envs
conda activate hemm
CUDA_VISIBLE_DEVICES=0 python main.py --model_key instruct_blip --batch_size 4
