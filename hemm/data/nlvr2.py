# -*- coding: utf-8 -*-
"""NLVR2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DnKPxGVYhObZBFK_5TLJpRPy85ciU3Z1
"""

from torch.utils.data import Dataset, DataLoader
import requests
from PIL import Image
from hemm.prompts.nlvr2prompt import NLVR2prompt
import os
import json
from typing import Optional, Union, List
from PIL import Image
import requests
import torch
from datasets import load_dataset
from tqdm import tqdm
import random

from hemm.data.dataset import HEMMDatasetEvaluator
from hemm.metrics.metric import HEMMMetric

class NLVR2evaluator(Dataset):
    def __init__(self,
                 train_json_path,
                 device,
                 ):
        self.train_json = [json.loads(line) for line in open(train_json_path).readlines()]
        self.device = device
        self.prompt = NLVR2prompt()

    def get_prompt(self, text):
        prompt_text = self.prompt.format_prompt(text)
        return prompt_text

    def evaluate_dataset(self,
                         model,
                         metric,
                         ) -> None:
        res = []
        gt=[]
        preds=[]
        for i in range(len(self.train_json)):
            left_url=self.train_json[i]['left_url']
            right_url=self.train_json[i]['right_url']
            label=self.train_json[i]['label']
            label=label.lower()
            sentence=self.train_json[i]['sentence']
            gt.append(label)
            try:
              img_1=Image.open(requests.get(left_url, stream=True).raw)
              img_2=Image.open(requests.get(right_url, stream=True).raw)
              size1=img_1.size
              size2=img_2.size
              avg_size=((size1[0]+size2[0])//2,(size1[1]+size2[1])//2)
              img_1 =img_1.resize(avg_size)
              img_2=img_2.resize(avg_size)
              image = Image.new('RGB',(2*avg_size[0],avg_size[1]), (255,255,255))
              image.paste(img_1,(0,0))
              image.paste(img_2,(avg_size[0],0))
            except:
              continue
            question=self.get_prompt(sentence)
            answer = model.generate({"image": image, "prompt": question})[0]
            answer =''.join(filter(str.isalpha, answer.lower()))
            #question = self.questions[index][f'query_{qu_k}']
            preds.append(answer)

        results = self.metric.compute(gt, preds)
        return results